{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "354d9e04-033f-468c-8fd0-2b5dc8774441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Transaction\n",
      "0  [citrus fruit, semi-finished bread, margarine,...\n",
      "1                   [tropical fruit, yogurt, coffee]\n",
      "2                                       [whole milk]\n",
      "3    [pip fruit, yogurt, cream cheese, meat spreads]\n",
      "4  [other vegetables, whole milk, condensed milk,...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'groceries.csv' with your actual file path)\n",
    "file_path = 'groceries.csv'  # Update this with the correct path\n",
    "groceries_data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Combine item columns into a list for each transaction, excluding NaNs\n",
    "groceries_data_cleaned = groceries_data.iloc[:, 1:].apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "\n",
    "# Convert to a DataFrame with a single column for transactions\n",
    "transactions_df = pd.DataFrame({'Transaction': groceries_data_cleaned})\n",
    "\n",
    "# Display the cleaned and restructured data\n",
    "print(transactions_df.head())\n",
    "\n",
    "# Save the cleaned data to a new CSV if needed\n",
    "transactions_df.to_csv('cleaned_groceries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0545a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "\n",
    "# Load and clean the dataset\n",
    "file_path = 'groceries.csv'  # Update with actual path\n",
    "groceries_data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Clean and restructure data\n",
    "groceries_data_cleaned = groceries_data.iloc[:, 1:].apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "\n",
    "# Convert to one-hot encoding format\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(groceries_data_cleaned).transform(groceries_data_cleaned)\n",
    "groceries_encoded = pd.DataFrame(te_data, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf69cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori - Find frequent itemsets and generate rules\n",
    "frequent_itemsets_apriori = apriori(groceries_encoded, min_support=0.005, use_colnames=True)\n",
    "rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"lift\", min_threshold=0.2,num_itemsets=num_itemsets)\n",
    "\n",
    "# FP-Growth - Find frequent itemsets and generate rules\n",
    "frequent_itemsets_fp = fpgrowth(groceries_encoded, min_support=0.005, use_colnames=True)\n",
    "rules_fp = association_rules(frequent_itemsets_fp, metric=\"lift\", min_threshold=0.2,num_itemsets=num_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03f01d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            antecedents                     consequents  \\\n",
      "3367          (root vegetables, yogurt)    (whole milk, tropical fruit)   \n",
      "2957          (root vegetables, yogurt)    (whole milk, tropical fruit)   \n",
      "2953  (tropical fruit, root vegetables)            (whole milk, yogurt)   \n",
      "3363  (tropical fruit, root vegetables)            (whole milk, yogurt)   \n",
      "2828       (pip fruit, root vegetables)  (other vegetables, whole milk)   \n",
      "\n",
      "      antecedent support  consequent support   support  confidence      lift  \\\n",
      "3367            0.025826            0.042298  0.005694    0.220472  5.212371   \n",
      "2957            0.025826            0.042298  0.005694    0.220472  5.212371   \n",
      "2953            0.021047            0.056024  0.005694    0.270531  4.828814   \n",
      "3363            0.021047            0.056024  0.005694    0.270531  4.828814   \n",
      "2828            0.015557            0.074835  0.005491    0.352941  4.716272   \n",
      "\n",
      "      representativity  leverage  conviction  zhangs_metric   jaccard  \\\n",
      "3367               1.0  0.004602    1.228567       0.829573  0.091205   \n",
      "2957               1.0  0.004602    1.228567       0.829573  0.091205   \n",
      "2953               1.0  0.004515    1.294059       0.809957  0.079772   \n",
      "3363               1.0  0.004515    1.294059       0.809957  0.079772   \n",
      "2828               1.0  0.004326    1.429801       0.800420  0.064671   \n",
      "\n",
      "      certainty  kulczynski  \n",
      "3367   0.186044    0.177544  \n",
      "2957   0.186044    0.177544  \n",
      "2953   0.227238    0.186082  \n",
      "3363   0.227238    0.186082  \n",
      "2828   0.300602    0.213155  \n"
     ]
    }
   ],
   "source": [
    "# Combine Apriori and FP-Growth rules\n",
    "combined_rules = pd.concat([rules_apriori, rules_fp], ignore_index=True)\n",
    "\n",
    "# Filter and display the best rules (lift > 1.5 and confidence > 0.2)\n",
    "filtered_rules = combined_rules[(combined_rules['lift'] > 1.5) & (combined_rules['confidence'] > 0.2)]\n",
    "print(filtered_rules.sort_values(by='lift', ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4fb42d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items for 'whole milk': ['whole milk', 'other vegetables', 'yogurt', 'root vegetables', 'rolls/buns']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# KNN to recommend products\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn.fit(groceries_encoded.T)  # Transpose to focus on products\n",
    "\n",
    "# Function to get recommended products\n",
    "def get_recommended_products(product_name, n_neighbors=5):\n",
    "    product_index = groceries_encoded.columns.get_loc(product_name)\n",
    "    distances, indices = knn.kneighbors(groceries_encoded.T.iloc[product_index].values.reshape(1, -1), n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the recommended products\n",
    "    recommended_products = [groceries_encoded.columns[i] for i in indices.flatten()]\n",
    "    return recommended_products\n",
    "\n",
    "# Ask the user for a product name and recommend related products\n",
    "product_name = input(\"Enter the product name: \")\n",
    "\n",
    "if product_name in groceries_encoded.columns:\n",
    "    recommended_products = get_recommended_products(product_name)\n",
    "    print(f\"Recommended items for '{product_name}': {recommended_products}\")\n",
    "else:\n",
    "    print(f\"Product '{product_name}' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fc280be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items for 'pip fruit' based on association rules:\n",
      "- other vegetables\n",
      "- root vegetables\n",
      "- tropical fruit\n",
      "- whole milk\n",
      "- yogurt\n",
      "\n",
      "Recommended items for 'pip fruit' based on KNN:\n",
      "- pip fruit\n",
      "- tropical fruit\n",
      "- whole milk\n",
      "- other vegetables\n",
      "- yogurt\n"
     ]
    }
   ],
   "source": [
    "# Combine Apriori and FP-Growth rules for better recommendations\n",
    "def recommend_items(product_name, rules, top_n=5):\n",
    "    product_name = product_name.lower()\n",
    "    \n",
    "    # Filter rules where the product appears in the antecedents\n",
    "    filtered_rules = rules[rules['antecedents'].apply(lambda x: any(product_name in item for item in x))]\n",
    "    \n",
    "    recommendations = [\n",
    "        ', '.join(consequent)  # Join all items in the consequents\n",
    "        for _, row in filtered_rules.head(top_n).iterrows()\n",
    "        for consequent in [row['consequents']]\n",
    "    ]\n",
    "    return recommendations\n",
    "\n",
    "# Interactive recommendation\n",
    "product_name = input(\"Enter the product name: \").strip()\n",
    "recommendations = recommend_items(product_name, filtered_rules)\n",
    "\n",
    "# Display recommendations from association rules\n",
    "if recommendations:\n",
    "    print(f\"Recommended items for '{product_name}' based on association rules:\")\n",
    "    for item in recommendations:\n",
    "        print(f\"- {item}\")\n",
    "else:\n",
    "    print(f\"No recommendations found for '{product_name}' based on association rules.\")\n",
    "    \n",
    "# Now, use KNN to get product recommendations\n",
    "if product_name in groceries_encoded.columns:\n",
    "    recommended_products_knn = get_recommended_products(product_name)\n",
    "    print(f\"\\nRecommended items for '{product_name}' based on KNN:\")\n",
    "    for product in recommended_products_knn:\n",
    "        print(f\"- {product}\")\n",
    "else:\n",
    "    print(f\"Product '{product_name}' not found in the dataset for KNN recommendations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ceb45046-2112-434a-93fc-8c738f1d524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          antecedents         consequents  antecedent support  \\\n",
      "0     (bottled water)          (UHT-milk)            0.110524   \n",
      "1          (UHT-milk)     (bottled water)            0.033452   \n",
      "2  (other vegetables)          (UHT-milk)            0.193493   \n",
      "3          (UHT-milk)  (other vegetables)            0.033452   \n",
      "4        (rolls/buns)          (UHT-milk)            0.183935   \n",
      "\n",
      "   consequent support   support  confidence      lift  representativity  \\\n",
      "0            0.033452  0.007321    0.066237  1.980074               1.0   \n",
      "1            0.110524  0.007321    0.218845  1.980074               1.0   \n",
      "2            0.033452  0.008134    0.042039  1.256694               1.0   \n",
      "3            0.193493  0.008134    0.243161  1.256694               1.0   \n",
      "4            0.033452  0.006406    0.034826  1.041071               1.0   \n",
      "\n",
      "   leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0  0.003624    1.035111       0.556472  0.053571   0.033920    0.142541  \n",
      "1  0.003624    1.138668       0.512099  0.053571   0.121781    0.142541  \n",
      "2  0.001662    1.008964       0.253267  0.037175   0.008884    0.142600  \n",
      "3  0.001662    1.065626       0.211331  0.037175   0.061585    0.142600  \n",
      "4  0.000253    1.001423       0.048343  0.030361   0.001421    0.113158  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Convert transactions to a one-hot encoded DataFrame\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions_df['Transaction']).transform(transactions_df['Transaction'])\n",
    "transactions_encoded = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori to find frequent itemsets\n",
    "frequent_itemsets = apriori(transactions_encoded, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Calculate the total number of itemsets\n",
    "num_itemsets = len(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=num_itemsets, metric=\"lift\", min_threshold=0.2)\n",
    "\n",
    "# Display the rules\n",
    "print(rules.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b94eb690-691d-45f5-af56-9addd42704da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          antecedents         consequents  antecedent support  \\\n",
      "5            (yogurt)        (whole milk)            0.139502   \n",
      "4        (whole milk)            (yogurt)            0.255516   \n",
      "0  (other vegetables)        (whole milk)            0.193493   \n",
      "1        (whole milk)  (other vegetables)            0.255516   \n",
      "\n",
      "   consequent support   support  confidence      lift  representativity  \\\n",
      "5            0.255516  0.056024    0.401603  1.571735               1.0   \n",
      "4            0.139502  0.056024    0.219260  1.571735               1.0   \n",
      "0            0.255516  0.074835    0.386758  1.513634               1.0   \n",
      "1            0.193493  0.074835    0.292877  1.513634               1.0   \n",
      "\n",
      "   leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "5  0.020379    1.244132       0.422732  0.165267   0.196226    0.310432  \n",
      "4  0.020379    1.102157       0.488608  0.165267   0.092688    0.310432  \n",
      "0  0.025394    1.214013       0.420750  0.200000   0.176286    0.339817  \n",
      "1  0.025394    1.140548       0.455803  0.200000   0.123228    0.339817  \n"
     ]
    }
   ],
   "source": [
    "# Filter rules with lift > 1.5 and confidence > 0.2\n",
    "filtered_rules = rules[(rules['lift'] > 1.5) & (rules['confidence'] > 0.2)]\n",
    "\n",
    "# Display the top rules\n",
    "print(filtered_rules.sort_values(by='lift', ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85d69904-97f0-4c97-bf91-4f10dac32b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          antecedents         consequents  antecedent support  \\\n",
      "0     (bottled water)          (UHT-milk)            0.110524   \n",
      "1          (UHT-milk)     (bottled water)            0.033452   \n",
      "2  (other vegetables)          (UHT-milk)            0.193493   \n",
      "3          (UHT-milk)  (other vegetables)            0.033452   \n",
      "4        (rolls/buns)          (UHT-milk)            0.183935   \n",
      "\n",
      "   consequent support   support  confidence      lift  representativity  \\\n",
      "0            0.033452  0.007321    0.066237  1.980074               1.0   \n",
      "1            0.110524  0.007321    0.218845  1.980074               1.0   \n",
      "2            0.033452  0.008134    0.042039  1.256694               1.0   \n",
      "3            0.193493  0.008134    0.243161  1.256694               1.0   \n",
      "4            0.033452  0.006406    0.034826  1.041071               1.0   \n",
      "\n",
      "   leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0  0.003624    1.035111       0.556472  0.053571   0.033920    0.142541  \n",
      "1  0.003624    1.138668       0.512099  0.053571   0.121781    0.142541  \n",
      "2  0.001662    1.008964       0.253267  0.037175   0.008884    0.142600  \n",
      "3  0.001662    1.065626       0.211331  0.037175   0.061585    0.142600  \n",
      "4  0.000253    1.001423       0.048343  0.030361   0.001421    0.113158  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=num_itemsets, metric=\"lift\", min_threshold=0.2)\n",
    "\n",
    "# Save association rules to CSV\n",
    "rules.to_csv('association_rules.csv', index=False)\n",
    "\n",
    "# Display the rules\n",
    "print(rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a53a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent itemsets (FP-Growth): 333\n",
      "        antecedents     consequents  antecedent support  consequent support  \\\n",
      "0      (whole milk)  (citrus fruit)            0.255516            0.082766   \n",
      "1    (citrus fruit)    (whole milk)            0.082766            0.255516   \n",
      "2          (yogurt)  (citrus fruit)            0.139502            0.082766   \n",
      "3    (citrus fruit)        (yogurt)            0.082766            0.139502   \n",
      "4  (tropical fruit)  (citrus fruit)            0.104931            0.082766   \n",
      "\n",
      "    support  confidence      lift  representativity  leverage  conviction  \\\n",
      "0  0.030503    0.119379  1.442377               1.0  0.009355    1.041577   \n",
      "1  0.030503    0.368550  1.442377               1.0  0.009355    1.179008   \n",
      "2  0.021657    0.155248  1.875752               1.0  0.010111    1.085803   \n",
      "3  0.021657    0.261671  1.875752               1.0  0.010111    1.165467   \n",
      "4  0.019929    0.189922  2.294702               1.0  0.011244    1.132280   \n",
      "\n",
      "   zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0       0.411963  0.099108   0.039917    0.243965  \n",
      "1       0.334375  0.099108   0.151829    0.243965  \n",
      "2       0.542570  0.107957   0.079023    0.208459  \n",
      "3       0.509009  0.107957   0.141975    0.208459  \n",
      "4       0.630358  0.118788   0.116826    0.215354  \n",
      "                            antecedents           consequents  \\\n",
      "31     (other vegetables, citrus fruit)     (root vegetables)   \n",
      "543          (other vegetables, yogurt)  (whipped/sour cream)   \n",
      "120  (other vegetables, tropical fruit)     (root vegetables)   \n",
      "270                              (beef)     (root vegetables)   \n",
      "32      (root vegetables, citrus fruit)    (other vegetables)   \n",
      "\n",
      "     antecedent support  consequent support   support  confidence      lift  \\\n",
      "31             0.028876            0.108998  0.010371    0.359155  3.295045   \n",
      "543            0.043416            0.071683  0.010168    0.234192  3.267062   \n",
      "120            0.035892            0.108998  0.012303    0.342776  3.144780   \n",
      "270            0.052466            0.108998  0.017387    0.331395  3.040367   \n",
      "32             0.017692            0.193493  0.010371    0.586207  3.029608   \n",
      "\n",
      "     representativity  leverage  conviction  zhangs_metric   jaccard  \\\n",
      "31                1.0  0.007224    1.390354       0.717225  0.081340   \n",
      "543               1.0  0.007056    1.212206       0.725409  0.096899   \n",
      "120               1.0  0.008391    1.355705       0.707403  0.092791   \n",
      "270               1.0  0.011668    1.332628       0.708251  0.120677   \n",
      "32                1.0  0.006948    1.949059       0.681990  0.051646   \n",
      "\n",
      "     certainty  kulczynski  \n",
      "31    0.280759    0.227152  \n",
      "543   0.175058    0.188018  \n",
      "120   0.262376    0.227825  \n",
      "270   0.249603    0.245455  \n",
      "32    0.486932    0.319903  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Apply FP-Growth to find frequent itemsets\n",
    "frequent_itemsets_fp = fpgrowth(transactions_encoded, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Calculate the total number of frequent itemsets\n",
    "num_itemsets_fp = len(frequent_itemsets_fp)\n",
    "\n",
    "# Print the number of itemsets\n",
    "print(f\"Number of frequent itemsets (FP-Growth): {num_itemsets_fp}\")\n",
    "\n",
    "# Generate association rules from the FP-Growth frequent itemsets\n",
    "rules_fp = association_rules(frequent_itemsets_fp, metric=\"lift\", min_threshold=0.05,num_itemsets=num_itemsets_fp)\n",
    "\n",
    "# Display the rules from FP-Growth\n",
    "print(rules_fp.head())\n",
    "\n",
    "# Filter rules with lift > 1.5 and confidence > 0.2\n",
    "filtered_rules_fp = rules_fp[(rules_fp['lift'] > 1.5) & (rules_fp['confidence'] > 0.2)]\n",
    "\n",
    "# Display the top rules from FP-Growth\n",
    "print(filtered_rules_fp.sort_values(by='lift', ascending=False).head())\n",
    "\n",
    "# Save the FP-Growth association rules to CSV\n",
    "filtered_rules_fp.to_csv('filtered_fp_growth_association_rules.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e5246ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          antecedents         consequents  antecedent support  \\\n",
      "0     (bottled water)          (UHT-milk)            0.110524   \n",
      "1          (UHT-milk)     (bottled water)            0.033452   \n",
      "2  (other vegetables)          (UHT-milk)            0.193493   \n",
      "3          (UHT-milk)  (other vegetables)            0.033452   \n",
      "4        (rolls/buns)          (UHT-milk)            0.183935   \n",
      "\n",
      "   consequent support   support  confidence      lift  representativity  \\\n",
      "0            0.033452  0.007321    0.066237  1.980074               1.0   \n",
      "1            0.110524  0.007321    0.218845  1.980074               1.0   \n",
      "2            0.033452  0.008134    0.042039  1.256694               1.0   \n",
      "3            0.193493  0.008134    0.243161  1.256694               1.0   \n",
      "4            0.033452  0.006406    0.034826  1.041071               1.0   \n",
      "\n",
      "   leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0  0.003624    1.035111       0.556472  0.053571   0.033920    0.142541  \n",
      "1  0.003624    1.138668       0.512099  0.053571   0.121781    0.142541  \n",
      "2  0.001662    1.008964       0.253267  0.037175   0.008884    0.142600  \n",
      "3  0.001662    1.065626       0.211331  0.037175   0.061585    0.142600  \n",
      "4  0.000253    1.001423       0.048343  0.030361   0.001421    0.113158  \n",
      "                            antecedents                     consequents  \\\n",
      "2957          (root vegetables, yogurt)    (whole milk, tropical fruit)   \n",
      "2953  (tropical fruit, root vegetables)            (whole milk, yogurt)   \n",
      "2828       (pip fruit, root vegetables)  (other vegetables, whole milk)   \n",
      "2884  (tropical fruit, root vegetables)  (other vegetables, whole milk)   \n",
      "2803    (root vegetables, citrus fruit)  (other vegetables, whole milk)   \n",
      "\n",
      "      antecedent support  consequent support   support  confidence      lift  \\\n",
      "2957            0.025826            0.042298  0.005694    0.220472  5.212371   \n",
      "2953            0.021047            0.056024  0.005694    0.270531  4.828814   \n",
      "2828            0.015557            0.074835  0.005491    0.352941  4.716272   \n",
      "2884            0.021047            0.074835  0.007016    0.333333  4.454257   \n",
      "2803            0.017692            0.074835  0.005796    0.327586  4.377460   \n",
      "\n",
      "      representativity  leverage  conviction  zhangs_metric   jaccard  \\\n",
      "2957               1.0  0.004602    1.228567       0.829573  0.091205   \n",
      "2953               1.0  0.004515    1.294059       0.809957  0.079772   \n",
      "2828               1.0  0.004326    1.429801       0.800420  0.064671   \n",
      "2884               1.0  0.005441    1.387748       0.792169  0.078947   \n",
      "2803               1.0  0.004472    1.375887       0.785453  0.066823   \n",
      "\n",
      "      certainty  kulczynski  \n",
      "2957   0.186044    0.177544  \n",
      "2953   0.227238    0.186082  \n",
      "2828   0.300602    0.213155  \n",
      "2884   0.279408    0.213542  \n",
      "2803   0.273196    0.202516  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Apply TransactionEncoder to transform the data\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions_df['Transaction']).transform(transactions_df['Transaction'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "transactions_encoded = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori to find frequent itemsets\n",
    "frequent_itemsets = apriori(transactions_encoded, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate association rules from the frequent itemsets\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.2,num_itemsets=num_itemsets)\n",
    "\n",
    "# Display the rules\n",
    "print(rules.head())\n",
    "\n",
    "# Filter rules with lift > 1.5 and confidence > 0.2\n",
    "filtered_rules = rules[(rules['lift'] > 1.5) & (rules['confidence'] > 0.2)]\n",
    "\n",
    "# Display the top rules\n",
    "print(filtered_rules.sort_values(by='lift', ascending=False).head())\n",
    "\n",
    "# Save the association rules to CSV\n",
    "filtered_rules.to_csv('association_rules.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "167a590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.3\n"
     ]
    }
   ],
   "source": [
    "import mlxtend\n",
    "print(mlxtend.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "34240d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 9835\n",
      "Number of unique items: 169\n",
      "Number of unique users: 9835\n",
      "Average transactions per user: 1.0\n",
      "Average items per transaction: 0.02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "file_path = 'groceries.csv'  # Replace with your actual file path\n",
    "groceries_data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Step 2: Cleaning and transforming the data\n",
    "# We're assuming that each row represents a transaction, and items are in columns starting from the 2nd column\n",
    "groceries_data_cleaned = groceries_data.iloc[:, 1:].apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "\n",
    "# Step 3: Let's assume each transaction corresponds to a \"userId\" and the items represent the products purchased.\n",
    "# For simplicity, we'll consider that we have one \"user\" per transaction. You can adjust this if you have more complex data.\n",
    "\n",
    "# Number of transactions = n_ratings\n",
    "n_transactions = len(groceries_data)\n",
    "\n",
    "# Number of unique items\n",
    "n_items = len(groceries_data.iloc[:, 1:].stack().unique())\n",
    "\n",
    "# Number of unique users (for simplicity, we'll consider each transaction as from a unique user)\n",
    "n_users = n_transactions  # If each row represents a unique transaction/user\n",
    "\n",
    "# Print the information\n",
    "print(f\"Number of transactions: {n_transactions}\")\n",
    "print(f\"Number of unique items: {n_items}\")\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Average transactions per user: {round(n_transactions/n_users, 2)}\")\n",
    "print(f\"Average items per transaction: {round(n_items/n_transactions, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fad977dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Instant food products  UHT-milk  abrasive cleaner  artif. sweetener  \\\n",
      "0                  False     False             False             False   \n",
      "1                  False     False             False             False   \n",
      "2                  False     False             False             False   \n",
      "3                  False     False             False             False   \n",
      "4                  False     False             False             False   \n",
      "\n",
      "   baby cosmetics  baby food   bags  baking powder  bathroom cleaner   beef  \\\n",
      "0           False      False  False          False             False  False   \n",
      "1           False      False  False          False             False  False   \n",
      "2           False      False  False          False             False  False   \n",
      "3           False      False  False          False             False  False   \n",
      "4           False      False  False          False             False  False   \n",
      "\n",
      "   ...  turkey  vinegar  waffles  whipped/sour cream  whisky  white bread  \\\n",
      "0  ...   False    False    False               False   False        False   \n",
      "1  ...   False    False    False               False   False        False   \n",
      "2  ...   False    False    False               False   False        False   \n",
      "3  ...   False    False    False               False   False        False   \n",
      "4  ...   False    False    False               False   False        False   \n",
      "\n",
      "   white wine  whole milk  yogurt  zwieback  \n",
      "0       False       False   False     False  \n",
      "1       False       False    True     False  \n",
      "2       False        True   False     False  \n",
      "3       False       False    True     False  \n",
      "4       False        True   False     False  \n",
      "\n",
      "[5 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a user-item matrix where each row represents a transaction and each column an item\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions_df['Transaction']).transform(transactions_df['Transaction'])\n",
    "user_item_matrix = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Display the user-item matrix\n",
    "print(user_item_matrix.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "231b4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries_data_cleaned = groceries_data.iloc[:, 1:].apply(lambda row: row.dropna().str.lower().tolist(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62b20e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix Shape: (9835, 169)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Create the user-item matrix\n",
    "user_item_matrix = transactions_df['Transaction'].apply(pd.Series)\\\n",
    "    .stack()\\\n",
    "    .reset_index(level=1, drop=True)\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={0: 'Item', 'index': 'TransactionID'})\\\n",
    "    .pivot_table(index='TransactionID', columns='Item', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Convert to a NumPy array for KNN\n",
    "user_item_array = user_item_matrix.values\n",
    "\n",
    "print(\"User-Item Matrix Shape:\", user_item_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "952de7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances:\n",
      " [[0.         0.29289322 0.29289322 0.42264973 0.42264973]\n",
      " [0.         0.1339746  0.18350342 0.22540333 0.33333333]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.29289322 0.29289322 0.29289322 0.33333333]\n",
      " [0.         0.29289322 0.29289322 0.29289322 0.29289322]]\n",
      "Indices:\n",
      " [[   0 7219 8837 6882 3613]\n",
      " [   1 3636 4094 7099 8999]\n",
      " [1786 8765 7633 4164 8513]\n",
      " [   3 4687 2871 2384 5332]\n",
      " [   4 5485 6343 8526 2899]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the KNN model\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=5)\n",
    "\n",
    "# Fit the model using the user-item matrix\n",
    "knn.fit(user_item_array)\n",
    "\n",
    "# Find the 5 nearest neighbors for each user\n",
    "distances, indices = knn.kneighbors(user_item_array, n_neighbors=5)\n",
    "\n",
    "print(\"Distances:\\n\", distances[:5])\n",
    "print(\"Indices:\\n\", indices[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ea4c382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trans            Item 1               Item 2          Item 3  \\\n",
      "0      1      citrus fruit  semi-finished bread       margarine   \n",
      "1      2    tropical fruit               yogurt          coffee   \n",
      "2      3        whole milk                  NaN             NaN   \n",
      "3      4         pip fruit               yogurt    cream cheese   \n",
      "4      5  other vegetables           whole milk  condensed milk   \n",
      "\n",
      "                     Item 4 Item 5 Item 6 Item 7 Item 8 Item 9  ... Item 23  \\\n",
      "0               ready soups    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
      "1                       NaN    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
      "2                       NaN    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
      "3              meat spreads    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
      "4  long life bakery product    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
      "\n",
      "  Item 24 Item 25 Item 26 Item 27 Item 28 Item 29 Item 30 Item 31 Item 32  \n",
      "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "0    [citrus fruit, semi-finished bread, margarine,...\n",
      "1                     [tropical fruit, yogurt, coffee]\n",
      "2                                         [whole milk]\n",
      "3      [pip fruit, yogurt, cream cheese, meat spreads]\n",
      "4    [other vegetables, whole milk, condensed milk,...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(groceries_data.head())\n",
    "print(groceries_data_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea7496",
   "metadata": {},
   "source": [
    "recommendation system on fpgrowth algrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e70e666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recommendations based on FP-Growth Algorithm ---\n",
      "1. whipped/sour cream\n",
      "2. soda\n",
      "3. curd\n",
      "4. whole milk\n",
      "5. sausage\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'groceries.csv'  # Update with your actual file path\n",
    "groceries_data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Clean and transform the data into a list of transactions\n",
    "groceries_data_cleaned = groceries_data.iloc[:, 1:].apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "\n",
    "# Apply TransactionEncoder to convert transactions into one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(groceries_data_cleaned).transform(groceries_data_cleaned)\n",
    "groceries_encoded = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Apply FP-Growth with lower support threshold\n",
    "frequent_itemsets_fp = fpgrowth(groceries_encoded, min_support=0.003, use_colnames=True)\n",
    "\n",
    "# Generate association rules from FP-Growth frequent itemsets\n",
    "rules_fp = association_rules(frequent_itemsets_fp, metric=\"lift\", min_threshold=0.05,num_itemsets=num_itemsets)\n",
    "\n",
    "# Filter the rules based on relaxed thresholds\n",
    "filtered_rules_fp = rules_fp[(rules_fp['lift'] > 1.0) & (rules_fp['confidence'] > 0.2)]\n",
    "\n",
    "# Function to recommend items based on FP-Growth association rules\n",
    "def recommend_items_fp(product_name, rules_fp, top_n=5):\n",
    "    product_name = product_name.lower()\n",
    "\n",
    "    # Filter rules where the product is in the antecedents\n",
    "    recommendations = []\n",
    "    for _, row in filtered_rules_fp.iterrows():\n",
    "        if product_name in row['antecedents']:\n",
    "            recommendations.extend(row['consequents'])\n",
    "\n",
    "    # Return the top N recommendations\n",
    "    return list(set(recommendations))[:top_n]\n",
    "\n",
    "# Get user input for product name\n",
    "product_name = input(\"Enter the product name for FP-Growth recommendations: \").strip()\n",
    "\n",
    "# Get recommendations from FP-Growth\n",
    "recommendations_fp = recommend_items_fp(product_name, filtered_rules_fp)\n",
    "\n",
    "# Display results for FP-Growth\n",
    "print(f\"\\n--- Recommendations based on FP-Growth Algorithm ---\")\n",
    "if recommendations_fp:\n",
    "    for i, rec in enumerate(recommendations_fp, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "else:\n",
    "    print(\"No recommendations found using FP-Growth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc43a08",
   "metadata": {},
   "source": [
    "recommendation system based on apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "656753e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recommendations based on Apriori Algorithm ---\n",
      "1. coffee\n",
      "2. pork\n",
      "3. whole milk\n",
      "4. frankfurter\n",
      "5. root vegetables\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the dataset (replace 'groceries.csv' with your actual file path)\n",
    "file_path = 'groceries.csv'  # Update with your actual file path\n",
    "groceries_data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Clean and transform the data into a list of transactions (excluding NaNs)\n",
    "groceries_data_cleaned = groceries_data.iloc[:, 1:].apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "\n",
    "# Apply TransactionEncoder to convert transactions into one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(groceries_data_cleaned).transform(groceries_data_cleaned)\n",
    "groceries_encoded = pd.DataFrame(te_data, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori - Find frequent itemsets with minimum support\n",
    "frequent_itemsets = apriori(groceries_encoded, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate association rules from Apriori\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.2,num_itemsets=num_itemsets)\n",
    "\n",
    "# Function to recommend items based on Apriori association rules\n",
    "def recommend_items_apriori(product_name, rules, top_n=5):\n",
    "    product_name = product_name.lower()\n",
    "\n",
    "    # Filter rules where the product is in the antecedents\n",
    "    recommendations = []\n",
    "    for _, row in rules.iterrows():\n",
    "        if product_name in row['antecedents']:\n",
    "            recommendations.extend(row['consequents'])\n",
    "\n",
    "    # Return the top N recommendations\n",
    "    return list(set(recommendations))[:top_n]\n",
    "\n",
    "# Get user input for product name\n",
    "product_name = input(\"Enter the product name for Apriori recommendations: \").strip().lower()\n",
    "\n",
    "# Get recommendations from Apriori\n",
    "recommendations_apriori = recommend_items_apriori(product_name, rules)\n",
    "\n",
    "# Display results for Apriori\n",
    "print(f\"\\n--- Recommendations based on Apriori Algorithm ---\")\n",
    "if recommendations_apriori:\n",
    "    for i, rec in enumerate(recommendations_apriori, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "else:\n",
    "    print(\"No recommendations found using Apriori.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f407fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_item_matrix: (9835, 169)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of user_item_matrix:\", user_item_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb1d2296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items for 'pip fruit':\n",
      "1. pip fruit\n",
      "2. tropical fruit\n",
      "3. whole milk\n",
      "4. other vegetables\n",
      "5. yogurt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# KNN to recommend products using the user-item matrix (groceries_encoded)\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "\n",
    "# Transpose to focus on products (columns) rather than transactions (rows)\n",
    "knn.fit(groceries_encoded.T)\n",
    "\n",
    "# Function to get recommended products based on a product name\n",
    "def get_recommended_products(product_name, groceries_encoded, n_neighbors=5):\n",
    "    # Check if the product exists in the dataset\n",
    "    if product_name not in groceries_encoded.columns:\n",
    "        print(f\"Product '{product_name}' not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    # Get the index of the product in the dataset\n",
    "    product_index = groceries_encoded.columns.get_loc(product_name)\n",
    "    \n",
    "    # Use the KNN model to find similar products\n",
    "    distances, indices = knn.kneighbors(groceries_encoded.T.iloc[product_index].values.reshape(1, -1), n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Get the recommended product names\n",
    "    recommended_products = [groceries_encoded.columns[i] for i in indices.flatten()]\n",
    "    return recommended_products\n",
    "\n",
    "# Ask the user for a product name and recommend related products\n",
    "product_name = input(\"Enter the product name: \").strip().lower()\n",
    "\n",
    "# Get the recommendations\n",
    "recommended_products = get_recommended_products(product_name, groceries_encoded)\n",
    "\n",
    "# Display the recommendations\n",
    "if recommended_products:\n",
    "    print(f\"Recommended items for '{product_name}':\")\n",
    "    for i, product in enumerate(recommended_products, 1):\n",
    "        print(f\"{i}. {product}\")\n",
    "else:\n",
    "    print(\"No recommendations found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc1154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
